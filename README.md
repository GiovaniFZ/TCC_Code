# Trabalho de ConclusÃ£o de Curso (TCC) sobre AnÃ¡lise Comparativa entre Modelos de InteligÃªncia Artificial
AvaliaÃ§Ã£o entre ChatGPT e Gemini aplicados Ã  engenharia de software 

## 1. IntroduÃ§Ã£o
O objetivo deste projeto â€” parte integrante do Trabalho de ConclusÃ£o de Curso â€” Ã© comparar o desempenho de diferentes LLMs (Large Language Models) em tarefas envolvendo cÃ³digo-fonte de linguagens amplamente utilizadas na engenharia de software.

A anÃ¡lise contempla trÃªs eixos fundamentais:

CompreensÃ£o de cÃ³digo

GeraÃ§Ã£o de cÃ³digo

AnÃ¡lise e correÃ§Ã£o de erros

Cada eixo possui 6 prompts especÃ­ficos, enviados aos modelos ChatGPT e Gemini, permitindo uma comparaÃ§Ã£o estruturada de suas capacidades, limitaÃ§Ãµes, consistÃªncia e precisÃ£o tÃ©cnica.

::: {align="center"}

ğŸ¤– ChatGPT vs Gemini
Um estudo comparativo baseado em qualidade, precisÃ£o e utilidade prÃ¡tica

ğŸš€ CompreensÃ£o â€¢ GeraÃ§Ã£o â€¢ DepuraÃ§Ã£o de CÃ³digo
:::

## Sobre o Projeto

Este projeto automatiza a execuÃ§Ã£o de prompts para ambos os modelos e captura suas respostas em formato Markdown, permitindo:

AvaliaÃ§Ã£o qualitativa (clareza, precisÃ£o, organizaÃ§Ã£o)

AvaliaÃ§Ã£o tÃ©cnica (correÃ§Ã£o lÃ³gica e sintÃ¡tica)

AvaliaÃ§Ã£o comparativa (vantagens e limitaÃ§Ãµes lado a lado)

ğŸ“ Estrutura Completa do Projeto
.
â”œâ”€â”€ codes/                     # Scripts principais de execuÃ§Ã£o
â”‚   â”œâ”€â”€ code_comprehension.py
â”‚   â”œâ”€â”€ code_generation.py
â”‚   â””â”€â”€ error_analysis.py
â”‚
â”œâ”€â”€ prompts/                   # Prompts divididos por categoria
â”‚   â”œâ”€â”€ code_comprehension/
â”‚   â”œâ”€â”€ code_generation/
â”‚   â””â”€â”€ error_analysis/
â”‚
â”œâ”€â”€ responses/
â”‚   â”œâ”€â”€ chatgpt/               # Respostas geradas pelo ChatGPT
â”‚   â””â”€â”€ gemini/                # Respostas geradas pelo Gemini
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

## Categorias de AnÃ¡lise
### 1. CompreensÃ£o de CÃ³digo

Avalia a capacidade do modelo de:

Explicar trechos de cÃ³digo

Descrever o fluxo lÃ³gico

Identificar estruturas importantes

Interpretar a intenÃ§Ã£o do programador

Inclui 6 prompts exclusivos

### 2. GeraÃ§Ã£o de CÃ³digo

Avalia a habilidade de:

Criar implementaÃ§Ãµes completas ou parciais

Utilizar boas prÃ¡ticas e padrÃµes de projeto

Seguir requisitos detalhados

Gerar cÃ³digo limpo, eficiente e funcional

Inclui 6 prompts exclusivos

### 3. AnÃ¡lise e CorreÃ§Ã£o de Erros

O modelo deve:

Localizar bugs e inconsistÃªncias

Justificar os problemas encontrados

Propor correÃ§Ãµes adequadas

Sugerir melhorias estruturais

Inclui 6 prompts exclusivos

### Como Executar as AnÃ¡lises
1. Instalar dependÃªncias
pip install -r requirements.txt

2. Executar as categorias
# CompreensÃ£o de cÃ³digo
python codes/code_comprehension.py

# GeraÃ§Ã£o de cÃ³digo
python codes/code_generation.py

# AnÃ¡lise de erros
python codes/error_analysis.py

## Modelos Suportados
Modelo	DiretÃ³rio das Respostas
ChatGPT	responses/chatgpt/
Gemini	responses/gemini/

As respostas sÃ£o armazenadas automaticamente em Markdown para facilitar leitura e anÃ¡lise comparativa.

PadrÃ£o dos Arquivos de Resposta

Todos os arquivos seguem a convenÃ§Ã£o:

response_[modelo]_[nÃºmero].md


Exemplo:

response_chatgpt_1.md


Cada arquivo contÃ©m:

O prompt avaliado

A resposta completa

MarcaÃ§Ã£o por categoria e modelo



